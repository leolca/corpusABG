{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "# check if ABG corpus was already downloaded\n",
    "# if not, download it\n",
    "if [ ! -f /tmp/Corpus_ABG.csv ]; then \n",
    "  wget -q https://raw.githubusercontent.com/SauronGuide/corpusABG/master/Corpus_ABG_Completo_Versao3.csv -O /tmp/Corpus_ABG.csv\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Check ABG Corpus file type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/Corpus_ABG.csv: UTF-8 Unicode (with BOM) text, with CRLF line terminators\n"
     ]
    }
   ],
   "source": [
    "file /tmp/Corpus_ABG.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Since it uses CRLF line terminators, it was probably created on Windows. This double line terminator is unnacessary and carries an extra byte (```\\r```, carriage return) that might appear as ```^M``` on Linux and create further problem.\n",
    "\n",
    "The BOM marker is also redundant, since it is possible to infer the endianness by a simple analysis of the data. The BOM marker (in UTF-8) is made of the three inicial bytes ```0xEF```,```0xBB```,```0xBF```.\n",
    "\n",
    "So let's start by removing both of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "tail --bytes=+4 /tmp/Corpus_ABG.csv | tr -d '\\r' > /tmp/CorpusABG.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Unfortunately the ABG corpus has many erros. We will try to fix some of them and leave many behind.\n",
    "\n",
    "The first error we found is empty lines, that appear as: ```,,,,,,,,,,,,,,,,```.\n",
    "\n",
    "Lets list them and remove them. We will use grep to find them and the parameter ```-n``` to print the line number, along the match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[K20608\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[K,\u001b[m\u001b[K,,,,,,,,,,,,,,,\n",
      "\u001b[32m\u001b[K20747\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[K,\u001b[m\u001b[K,,,,,,,,,,,,,,,\n",
      "\u001b[32m\u001b[K20957\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[K,\u001b[m\u001b[K,,,,,,,,,,,,,,,\n",
      "\u001b[32m\u001b[K48422\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[K,\u001b[m\u001b[K,,,,,,,,,,,,,,,\n",
      "\u001b[32m\u001b[K48764\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[K,\u001b[m\u001b[K,,,,,,,,,,,,,,,\n",
      "\u001b[32m\u001b[K49034\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[K,\u001b[m\u001b[K,,,,,,,,,,,,,,,\n",
      "\u001b[32m\u001b[K49705\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[K,\u001b[m\u001b[K,,,,,,,,,,,,,,,\n",
      "\u001b[32m\u001b[K49838\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[K,\u001b[m\u001b[K,,,,,,,,,,,,,,,\n",
      "\u001b[32m\u001b[K50175\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[K,\u001b[m\u001b[K,,,,,,,,,,,,,,,\n",
      "\u001b[32m\u001b[K51587\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[K,\u001b[m\u001b[K,,,,,,,,,,,,,,,\n",
      "\u001b[32m\u001b[K53205\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[K,\u001b[m\u001b[K,,,,,,,,,,,,,,,\n",
      "\u001b[32m\u001b[K92625\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[K,\u001b[m\u001b[K,   ,,,,,,,,,,,,,,\n"
     ]
    }
   ],
   "source": [
    "grep -n '^,' /tmp/CorpusABG.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Now, lets remove those lines. We're using the same command from above and cutting the result to get only the line number. Then we peform a loop on those numbers to create a string with everything we will remove using ```sed```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "LINES=\"\"; \n",
    "for i in `grep -n '^,' /tmp/CorpusABG.csv | cut -d: -f1`; do \n",
    "  LINES=\"${LINES}${i}d;\"; \n",
    "done; \n",
    "sed -ie \"${LINES}\" /tmp/CorpusABG.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "The corpus has a sequence of commas ```,,,,,``` in the end of each line. We will remove it, since it is unused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sed -i 's/,,,,,$//g' /tmp/CorpusABG.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "The fields (columns) in the ABG corpus are listed on the first line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID,PALAVRA,CATMORF,LEMA,TRANSCRICAO,ACENTUACAO,ESTSILABICA,CATACENTUAL,FREQGERAL,FREQORAL,FREQESCRITA,Freq_Nivel\n"
     ]
    }
   ],
   "source": [
    "head -n 1 /tmp/CorpusABG.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "There are 12 fields: ID (1), PALAVRA (2), CATMORF (3), LEMA (4), TRANSCRICAO (5), ACENTUACAO (6), ESTSILABICA (7), CATACENTUAL (8), FREQGERAL (9), FREQORAL (10), FREQESCRITA (11), Freq_Nivel (12).\n",
    "\n",
    "Another type of error we found in the database is lines that don't have exactly 12 fields (3 have more than 12 and 3 have less than 12). Probably the authors have inserted erroneous commas or have missed some, creating a malformed file. The script bellow present the rows that do not have 12 fields. We also print the line number, so we may once again remove the bad data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24089:24093,Jereissati,   F   jereissati,   &je-reJ-sa-Ti*,   &je-reJ-s1-Ty*,   &CV-CVG-CV-CV*,   parox?tona,6,   0o,6,2\n",
      "35806:35816,Fuentes,   F   Fuentes,   &fE-tes*,   &fE-t4s*,   &CV-CVS*,   ox?tona,3,   0o,3,2\n",
      "46495:46508,prociss?es,   NP,,   prociss?es,   &pro-si-sOJs*,   &pro-si-s#Js*,   &CCV-CV-CVGS*,   ox?tona,2,2,   0e,2\n",
      "51341:51359,Josh,   F   Josh,   &jo-Sy*,   &j9-Sy*,   &CV-CV*,   parox?tona,2,   0o,2,2\n",
      "54571:54607,Juvenile,   NOM,   Juvenile,   &ju-ve-ni-le*,   &ju-ve-n7-ly*,   &CV-CV-CV-CV*,   parox?tona,1,   0o,1,,54607\n",
      "77325:77959,bulut,   F,   bulut,   &bu-lut*,   &bu-l$t*,   &CV-CVC*,   ox?tona,1,   0o,1,1,,1,   0o,1,1\n"
     ]
    }
   ],
   "source": [
    "cat /tmp/CorpusABG.csv | sed 's/,\\+\\s*$//' | awk -F, 'NF!=12{print NR\":\"$0}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Lets then remove those lines, just as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "LINES=\"\"; \n",
    "for i in `sed 's/,\\+\\s*$//' < /tmp/Corpus_ABG.csv | awk -F, 'NF!=12{print NR\":\"$0}' | cut -d: -f1`; do \n",
    "  LINES=\"${LINES}${i}d;\"; \n",
    "done; \n",
    "sed -ie \"${LINES}\" /tmp/CorpusABG.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "There are also rows where the FREQGERAL is zero or not a number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24086:24093,Jereissati,   F   jereissati,   &je-reJ-sa-Ti*,   &je-reJ-s1-Ty*,   &CV-CVG-CV-CV*,   parox?tona,6,   0o,6,2\n",
      "35802:35816,Fuentes,   F   Fuentes,   &fE-tes*,   &fE-t4s*,   &CV-CVS*,   ox?tona,3,   0o,3,2\n",
      "46490:46508,prociss?es,   NP,,   prociss?es,   &pro-si-sOJs*,   &pro-si-s#Js*,   &CCV-CV-CVGS*,   ox?tona,2,2,   0e,2\n",
      "51329:51359,Josh,   F   Josh,   &jo-Sy*,   &j9-Sy*,   &CV-CV*,   parox?tona,2,   0o,2,2\n"
     ]
    }
   ],
   "source": [
    "awk -F, '$9<1{print NR\":\"$0}' < /tmp/CorpusABG.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "We're going to remove these data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "LINES=\"\"; \n",
    "for i in `awk -F, '$9<1{print NR\":\"$0}' < /tmp/CorpusABG.csv | cut -d: -f1`; do \n",
    "  LINES=\"${LINES}${i}d;\"; \n",
    "done; \n",
    "sed -ie \"${LINES}\" /tmp/CorpusABG.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "There are other frequency fields (FREQORAL (10), FREQESCRITA (11), Freq_Nivel (12)) and theit values should be numeric and positive. But many have non valid values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71043\n"
     ]
    }
   ],
   "source": [
    "awk -F, '($10<1||$11<1||$12<1){print NR\":\"$0}' < /tmp/CorpusABG.csv | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "This number represents a large amount of the total dada. We will leave it be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".76726931052358735095\n"
     ]
    }
   ],
   "source": [
    "TOTAL=$(wc -l /tmp/CorpusABG.csv | cut -d' ' -f1)\n",
    "COUNTNN=$(awk -F, '($10<1||$11<1||$12<1){print NR\":\"$0}' < /tmp/CorpusABG.csv | wc -l)\n",
    "echo \"$COUNTNN/$TOTAL\" | bc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "The morphological category (column 3) and stress category (column 8) are categorical variables, they might have values in a finite set and their value assigning each sample to a different group. Lets check the values used in the corpus.\n",
    "\n",
    "\n",
    "Morphological category (column 3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  36563 NOM\n",
      "  32776 V\n",
      "  11681 ADJ\n",
      "   5067 F\n",
      "   2188 V+P\n",
      "   1456 C\n",
      "   1061 ADV\n",
      "    717 \n",
      "    430 G\n",
      "    184 P\n",
      "    179 I\n",
      "     80 PREP+P\n",
      "     55 CONJ\n",
      "     42 NUM\n",
      "     39 PREP\n",
      "     38 PREP+DET\n",
      "     27 DET\n",
      "      5 PREP+ADV\n",
      "      1 V+p\n",
      "      1 FNOM\n",
      "      1 f\n",
      "      1 CATMORF\n"
     ]
    }
   ],
   "source": [
    "awk -F',[ ]*' '{print $3}' /tmp/CorpusABG.csv | sort | uniq -c | sort -rn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "We see there 717 with no morphological category assigned, there is one \"V+p\" that might be \"V+P\" and a \"f\" that might be \"F\". We might easily correct those two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "awk -F',[ ]*' 'BEGIN{OFS=\", \"} ($3==\"f\"){$3=\"F\"} ($3==\"V+p\"){$3=\"V+P\"} {print}' /tmp/CorpusABG.csv > /tmp/tmpABG\n",
    "mv /tmp/tmpABG /tmp/CorpusABG.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "The list of the 717 of entries with empty morphological category (column 3) is given bellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 legal\t\t395 crian?as\t\t634 logo\n",
      "149 segundo\t\t396 pol?cia\t\t635 estados\n",
      "150 vida\t\t397 sala\t\t636 velho\n",
      "151 outros\t\t398 p?blico\t\t637 m?dico\n",
      "152 nunca\t\t399 enquanto\t\t638 a??o\n",
      "153 foram\t\t400 nosso\t\t639 mal\n",
      "154 ?poca\t\t401 junto\t\t640 votos\n",
      "155 ia\t\t\t402 sul\t\t\t641 sociedade\n",
      "156 S?o\t\t\t403 falava\t\t642 alunos\n",
      "157 disse\t\t404 quarto\t\t643 relacionadas\n",
      "158 est?o\t\t405 situa??o\t\t644 pequena\n",
      "159 fui\t\t\t406 talvez\t\t645 aquelas\n",
      "160 tipo\t\t407 social\t\t646 debate\n",
      "161 ir\t\t\t408 conhece\t\t647 gostoso\n",
      "162 quer\t\t409 seguran?a\t\t648 trabalhando\n",
      "163 dentro\t\t410 umas\t\t649 antigamente\n",
      "164 pessoal\t\t411 idade\t\t650 quiser\n",
      "165 ficou\t\t412 m?s\t\t\t651 dilma\n",
      "166 d?\t\t\t413 dados\t\t652 papel\n",
      "167 ver\t\t\t414 for\t\t\t653 l?ngua\n",
      "168 dizer\t\t415 podem\t\t654 equipe\n",
      "169 falei\t\t416 Mas\t\t\t655 saiu\n",
      "170 maior\t\t417 bairros\t\t656 seguinte\n",
      "171 seus\t\t418 importante\t\t657 cinema\n",
      "172 entendeu\t\t419 filha\t\t658 pensar\n",
      "173 teve\t\t420 pouquinho\t\t659 ruim\n",
      "174 jeito\t\t421 conhe?o\t\t660 eleitoral\n",
      "175 tanto\t\t422 curso\t\t661 cidades\n",
      "176 essas\t\t423 processo\t\t662 ideia\n",
      "177 aos\t\t\t424 carioca\t\t663 estudo\n",
      "178 lado\t\t425 sistema\t\t664 esta\n",
      "179 carro\t\t426 irm?\t\t665 irm?os\n",
      "180 hist?ria\t\t427 trabalha\t\t666 mostra\n",
      "181 perto\t\t428 afirmou\t\t667 Se\n",
      "182 pa?s\t\t429 valor\t\t668 minhas\n",
      "183 senhora\t\t430 existe\t\t669 entendendo\n",
      "184 melhor\t\t431 turno\t\t670 respeito\n",
      "185 hora\t\t432 pais\t\t671 morreu\n",
      "186 tal\t\t\t433 fato\t\t672 novas\n",
      "187 cada\t\t434 amigo\t\t673 alto\n",
      "188 aquela\t\t435 tive\t\t674 pre?o\n",
      "189 mim\t\t\t436 sido\t\t675 preciso\n",
      "190 antes\t\t437 principalmente\t676 principais\n",
      "191 sim\t\t\t438 m?o\t\t\t677 popula??o\n",
      "192 brasil\t\t439 PAULO\t\t678 tiver\n",
      "193 presidente\t\t440 poss?vel\t\t679 desta\n",
      "194 contra\t\t441 f?cil\t\t680 palavra\n",
      "195 pro\t\t\t442 mudou\t\t681 prefeito\n",
      "196 te\t\t\t443 brasileiro\t\t682 leste\n",
      "197 estado\t\t444 pesquisa\t\t683 diretor\n",
      "198 cara\t\t445 pr?ximo\t\t684 gra?as\n",
      "199 aquele\t\t446 Estado\t\t685 lazer\n",
      "200 fez\t\t\t447 uso\t\t\t686 ler\n",
      "201 gosta\t\t448 cerca\t\t687 mudan?a\n",
      "202 algum\t\t449 per?odo\t\t688 tivesse\n",
      "203 ?gua\t\t450 tinham\t\t689 justi?a\n",
      "204 v?\t\t\t451 espa?o\t\t690 super\n",
      "205 daqui\t\t452 entrar\t\t691 telefone\n",
      "206 rua\t\t\t453 contato\t\t692 col?gio\n",
      "207 forma\t\t454 estudar\t\t693 dizendo\n",
      "208 desde\t\t455 homem\t\t694 clube\n",
      "209 caso\t\t456 empresas\t\t695 ?ltimos\n",
      "210 trabalhar\t\t457 menina\t\t696 entender\n",
      "211 semana\t\t458 programa\t\t697 por?m\n",
      "212 fora\t\t459 tarde\t\t698 come?ar\n",
      "213 dif?cil\t\t460 vila\t\t699 vinha\n",
      "214 vamos\t\t461 afirma\t\t700 necessidade\n",
      "215 certo\t\t462 posso\t\t701 usar\n",
      "216 queria\t\t463 acabou\t\t702 p?ssaro\n",
      "217 verdade\t\t464 in?cio\t\t703 terra\n",
      "218 problema\t\t465 manh?\t\t704 comiss?o\n",
      "220 senhor\t\t466 acaba\t\t705 vejo\n",
      "221 Dilma\t\t467 metr?\t\t706 bilh?es\n",
      "222 diferente\t\t468 sentido\t\t707 crise\n",
      "223 primeira\t\t469 setembro\t\t708 percebe\n",
      "224 concordando\t\t470 acontece\t\t709 casos\n",
      "225 filho\t\t471 praia\t\t710 atual\n",
      "226 novo\t\t472 consegue\t\t711 presente\n",
      "227 dar\t\t\t473 inf?ncia\t\t712 nenhuma\n",
      "228 qual\t\t474 trabalhava\t\t713 cozinha\n",
      "229 dinheiro\t\t475 opini?o\t\t714 ajuda\n",
      "230 vem\t\t\t476 projeto\t\t715 hor?rio\n",
      "231 uns\t\t\t477 v?rias\t\t716 p?blica\n",
      "232 paulistano\t\t478 capital\t\t717 menino\n",
      "233 rio\t\t\t479 apesar\t\t718 tendo\n",
      "234 regi?o\t\t480 p?\t\t\t719 t?cnico\n",
      "235 deve\t\t481 monte\t\t720 transporte\n",
      "236 interior\t\t482 comigo\t\t721 liberdade\n",
      "237 frente\t\t483 vontade\t\t722 desses\n",
      "238 qualquer\t\t484 banco\t\t723 buscar\n",
      "239 outras\t\t485 igreja\t\t724 escolas\n",
      "240 conta\t\t486 sabia\t\t725 professores\n",
      "242 final\t\t487 falo\t\t726 dava\n",
      "243 numa\t\t488 deixar\t\t727 simples\n",
      "244 olha\t\t489 alta\t\t728 fazenda\n",
      "246 ap?s\t\t490 pegou\t\t729 tentar\n",
      "247 DE\t\t\t491 produ??o\t\t730 houve\n",
      "248 grupo\t\t492 este\t\t731 acesso\n",
      "249 noite\t\t493 n?mero\t\t732 italiano\n",
      "250 t?o\t\t\t494 s?rie\t\t733 jornal\n",
      "251 esses\t\t495 pega\t\t734 entrou\n",
      "252 quase\t\t496 aula\t\t735 avenida\n",
      "253 falando\t\t497 v?rios\t\t736 shopping\n",
      "254 dias\t\t498 marido\t\t737 algo\n",
      "255 Paulo\t\t499 poderia\t\t738 aumento\n",
      "256 rela??o\t\t500 pois\t\t739 fizeram\n",
      "257 quanto\t\t501 servi?o\t\t740 novos\n",
      "258 porta\t\t502 problemas\t\t741 amiga\n",
      "260 filhos\t\t503 comprar\t\t742 leva\n",
      "261 sotaque\t\t504 palavras\t\t743 movimento\n",
      "262 Brasil\t\t505 voltar\t\t744 sob\n",
      "263 alguns\t\t506 festa\t\t745 constru??o\n",
      "264 mulher\t\t507 prefeitura\t\t746 praticamente\n",
      "265 causa\t\t508 brasileira\t\t747 recursos\n",
      "266 chegou\t\t509 realmente\t\t748 sexta\n",
      "267 morar\t\t510 cabe?a\t\t749 ter?\n",
      "268 ?nibus\t\t511 levar\t\t750 a??es\n",
      "269 No\t\t\t512 m?sica\t\t751 morei\n",
      "270 pol?tica\t\t513 comecei\t\t752 entra\n",
      "271 t?\t\t\t514 experi?ncia\t\t753 deveria\n",
      "272 algu?m\t\t515 teria\t\t754 depende\n",
      "273 crian?a\t\t516 gostaria\t\t755 passando\n",
      "274 ningu?m\t\t517 federal\t\t756 corpo\n",
      "275 seja\t\t518 pr?dio\t\t757 casas\n",
      "276 boa\t\t\t519 lei\t\t\t758 parque\n",
      "277 A?cio\t\t520 pa?ses\t\t759 aluno\n",
      "279 ai\t\t\t521 s?bado\t\t760 exatamente\n",
      "280 mesma\t\t522 podia\t\t761 texto\n",
      "281 entendi\t\t523 ensino\t\t762 roupa\n",
      "282 ser?\t\t524 portugu?s\t\t763 continua\n",
      "283 t?m\t\t\t525 claro\t\t764 naquele\n",
      "284 seria\t\t526 pelas\t\t765 deixou\n",
      "285 veio\t\t527 demais\t\t766 entanto\n",
      "286 falam\t\t528 campo\t\t767 p?e\n",
      "287 apenas\t\t529 deste\t\t768 rela??es\n",
      "288 suas\t\t530 naquela\t\t769 jardim\n",
      "290 toda\t\t531 pr?prio\t\t770 estad?o\n",
      "291 embora\t\t532 povo\t\t771 caf?\n",
      "292 poder\t\t533 igual\t\t772 agosto\n",
      "294 da?\t\t\t534 filme\t\t773 imagem\n",
      "295 voc?s\t\t535 normal\t\t774 pol?ticos\n",
      "296 falta\t\t536 medo\t\t775 ganhar\n",
      "297 sou\t\t\t537 obra\t\t776 pior\n",
      "298 lembro\t\t538 come?a\t\t777 Como\n",
      "299 fazendo\t\t539 pagar\t\t778 brincava\n",
      "300 ?rea\t\t540 chama\t\t779 entende\n",
      "301 mercado\t\t541 bonito\t\t780 viajar\n",
      "302 irm?o\t\t542 sai\t\t\t781 coloca\n",
      "303 come?ou\t\t543 geral\t\t782 especial\n",
      "304 deu\t\t\t544 Segundo\t\t783 vit?ria\n",
      "305 horas\t\t545 resultado\t\t784 comida\n",
      "306 algumas\t\t546 contar\t\t785 terceiro\n",
      "307 durante\t\t547 modo\t\t786 ingl?s\n",
      "308 centro\t\t548 cultura\t\t787 aonde\n",
      "309 amigos\t\t549 emprego\t\t788 barcelona\n",
      "311 todas\t\t550 ru?do\t\t789 leite\n",
      "312 jogo\t\t551 maneira\t\t790 disputa\n",
      "313 fiquei\t\t552 mudar\t\t791 vendo\n",
      "314 fim\t\t\t553 grandes\t\t792 ministro\n",
      "315 deixa\t\t554 aberta\t\t793 De\n",
      "316 qu?\t\t\t555 Ele\t\t\t794 trabalhei\n",
      "317 empresa\t\t556 vi\t\t\t795 conseguiu\n",
      "318 acordo\t\t557 forte\t\t796 voltou\n",
      "319 meses\t\t558 inclusive\t\t797 reuni?o\n",
      "320 volta\t\t559 preto\t\t798 achei\n",
      "321 elas\t\t560 futebol\t\t799 dando\n",
      "322 sair\t\t561 janeiro\t\t800 levou\n",
      "323 muitos\t\t562 hospital\t\t801 internet\n",
      "324 lugares\t\t563 folha\t\t802 cinquenta\n",
      "325 campanha\t\t564 conhecer\t\t803 r?pido\n",
      "326 paulista\t\t565 aten??o\t\t804 linha\n",
      "327 fazia\t\t566 Marina\t\t805 casamento\n",
      "328 eram\t\t567 longe\t\t806 pensa\n",
      "329 sendo\t\t568 partido\t\t807 setor\n",
      "330 al?m\t\t569 interessante\t808 apartamento\n",
      "331 meus\t\t570 jogar\t\t809 mundial\n",
      "332 quest?o\t\t571 contou\t\t810 brasileiros\n",
      "333 saber\t\t572 ?ltimo\t\t811 favor\n",
      "334 passar\t\t573 candidato\t\t812 ?nica\n",
      "335 outubro\t\t574 aqueles\t\t813 caminho\n",
      "336 chegar\t\t575 elei??o\t\t814 queda\n",
      "337 nome\t\t576 encontro\t\t815 peguei\n",
      "338 estar\t\t577 menor\t\t816 Um\n",
      "339 mora\t\t578 quais\t\t817 longo\n",
      "340 dez\t\t\t579 elei??es\t\t818 livre\n",
      "341 precisa\t\t580 classe\t\t819 informa??es\n",
      "342 c?\t\t\t581 m?dia\t\t820 medida\n",
      "343 milh?es\t\t582 principal\t\t821 maria\n",
      "344 educa??o\t\t583 norte\t\t822 narrativa\n",
      "345 neg?cio\t\t584 lembra\t\t823 complicado\n",
      "346 quero\t\t585 pr?pria\t\t824 companhia\n",
      "347 barulho\t\t586 estavam\t\t825 tranquilo\n",
      "348 momento\t\t587 sociais\t\t826 nota\n",
      "349 maioria\t\t588 nasceu\t\t827 plano\n",
      "350 aconteceu\t\t589 televis?o\t\t828 come?o\n",
      "351 tr?nsito\t\t590 tirar\t\t829 faixa\n",
      "352 atr?s\t\t591 moradores\t\t830 tema\n",
      "353 partir\t\t592 temos\t\t831 petista\n",
      "354 passa\t\t593 errado\t\t832 quarta\n",
      "355 ficava\t\t594 viagem\t\t833 site\n",
      "356 muitas\t\t595 apoio\t\t834 geralmente\n",
      "357 segunda\t\t596 tucano\t\t835 inteiro\n",
      "358 ponto\t\t597 professora\t\t836 conseguir\n",
      "359 nova\t\t598 com\t\t\t837 gest?o\n",
      "360 parece\t\t599 mooca\t\t838 solu??o\n",
      "361 Para\t\t600 livro\t\t839 costa\n",
      "362 nenhum\t\t601 fazem\t\t840 som\n",
      "363 v?o\t\t\t602 renda\t\t841 lista\n",
      "364 feito\t\t603 tomar\t\t842 possibilidade\n",
      "365 aquilo\t\t604 for?a\t\t843 via\n",
      "366 fundo\t\t605 vim\t\t\t844 engra?ado\n",
      "367 sa?de\t\t606 moram\t\t845 certa\n",
      "368 domingo\t\t607 vista\t\t846 morou\n",
      "369 tenha\t\t608 colocar\t\t847 obras\n",
      "370 fosse\t\t609 fa?o\t\t848 ordem\n",
      "371 local\t\t610 andar\t\t849 sele??o\n",
      "372 pegar\t\t611 base\t\t850 Lula\n",
      "373 pontos\t\t612 Rio\t\t\t851 relato\n",
      "374 neste\t\t613 comer\t\t852 feita\n",
      "375 diferen?a\t\t614 internacional\t853 morte\n",
      "376 pelos\t\t615 time\t\t854 estadual\n",
      "377 havia\t\t616 n?vel\t\t855 direitos\n",
      "378 deus\t\t617 mulheres\t\t856 teatro\n",
      "379 gostava\t\t618 decis?o\t\t857 devem\n",
      "380 faculdade\t\t619 vieram\t\t858 a?cio\n",
      "381 minutos\t\t620 pequeno\t\t859 origem\n",
      "382 economia\t\t621 nacional\t\t860 Neves\n",
      "383 passou\t\t622 diferentes\t\t861 carros\n",
      "384 cima\t\t623 qualidade\t\t862 celular\n",
      "385 direito\t\t624 pol?tico\t\t863 tia\n",
      "386 morava\t\t625 dessas\t\t864 ficam\n",
      "387 chega\t\t626 governador\t\t865 an?lise\n",
      "388 passado\t\t627 crescimento\t\t866 caixa\n",
      "389 fiz\t\t\t628 ?ltima\t\t867 parar\n",
      "390 Na\t\t\t629 ajudar\t\t868 conhecimento\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391 professor\t\t630 entrevista\t\t869 obrigada\n",
      "392 viol?ncia\t\t631 condi??es\t\t870 Petrobras\n",
      "393 viu\t\t\t632 certeza\t\t871 guerra\n",
      "394 zona\t\t633 baixo\t\t872 poucos\n"
     ]
    }
   ],
   "source": [
    "awk -F',[ ]*' '($3==\"\"){print $1,$2}' /tmp/CorpusABG.csv | column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Stress category (column 8):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  55262 parox?tona\n",
      "  21694 ox?tona\n",
      "   6800 paroxitona\n",
      "   3470 oxitona\n",
      "   3392 proparox?tona\n",
      "   1530 mono\n",
      "    396 proparoxitona\n",
      "     40 4\n",
      "      2 PARox?tona\n",
      "      2 ox?tono\n",
      "      1 quatro\n",
      "      1 parox?ton\n",
      "      1 parox?ona\n",
      "      1 CATACENTUAL\n"
     ]
    }
   ],
   "source": [
    "awk -F',[ ]*' '{print $8}' /tmp/CorpusABG.csv | sort | uniq -c | sort -rn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "There are 40 entries with value 4 for stress category, one entry with value 'quatro' (might be the same as 4) and there are many mistyped names which we might correct with a simple substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "# fix stress category\n",
    "sed -i 's/ox?tona/oxitona/g' /tmp/CorpusABG.csv\n",
    "sed -i 's/ox?tono/oxitona/g' /tmp/CorpusABG.csv\n",
    "sed -i 's/PARoxitona/paroxitona/g' /tmp/CorpusABG.csv\n",
    "sed -i 's/parox?ona/paroxitona/g' /tmp/CorpusABG.csv\n",
    "sed -i 's/parox?ton/paroxitona/g' /tmp/CorpusABG.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Now, lets check some of those entries with value 4 in stress category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "719,t?cnico,,   t?cnico,   &t5-ky-ni-ko*,   &t5-ky-ny-kw*,   &CV-CV-CV-CV*,4,500,151,349,3\n",
      "1485,t?cnica,   NOM,   t?cnica,   &t5-ky-ni-ka*,   &t5-ky-ny-k@*,   &CV-CV-CV-CV*,4,231,70,161,3\n",
      "2666,t?cnicos,   ADJ,   t?cnicos,   &t5-ky-ni-kos*,   &t5-ky-ny-kws*,   &CV-CV-CV-CVS*,4,121,13,108,3\n",
      "4111,t?cnicas,   ADJ,   t?cnicas,   &t5-ky-ni-kas*,   &t5-ky-ny-k@s*,   &CV-CV-CV-CVC*,4,73,11,62,2\n",
      "5060,d?ficit,   NOM,   d?ficit,   &d5-fi-si-ty*,   &d5-fy-sy-ty*,   &CV-CV-CV-CV*,4,56,3,53,2\n"
     ]
    }
   ],
   "source": [
    "awk -F',[ ]*' '($8==4){print}' /tmp/CorpusABG.csv | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "And the complete list of words with value 4 (or 'quatro') in stress category is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "719 t?cnico\t\t31949 Polit?cnica\t56961 antiss?ptico\n",
      "1485 t?cnica\t\t34472 eletrot?cnico\t57174 antiss?pticos\n",
      "2666 t?cnicos\t\t34935 ?tnicas\t\t57581 apocal?pticas\n",
      "4111 t?cnicas\t\t41512 aut?ctones\t59961 c?psula\n",
      "5060 d?ficit\t\t42759 eletrot?cnica\t64142 el?ptico\n",
      "13979 l?xico\t\t43225 el?ptica\t\t64157 epil?ptica\n",
      "16379 polit?cnica\t44164 ex-t?cnico\t64278 epil?pticos\n",
      "16904 ?tnica\t\t46546 logar?tmica\t72143 lepid?pteros\n",
      "19590 inc?gnita\t\t50151 pan?ptico\t\t74419 g?ngsteres\n",
      "21275 ?tnicos\t\t51463 r?tmico\t\t77274 multi?tnico\n",
      "23465 ?tnico\t\t51627 sociot?cnica\t83538 d?couvert\n",
      "26420 inc?gnito\t\t56107 h?bitat\t\t84891 pirot?cnicos\n",
      "28814 apocal?ptica\t56835 anal?pticos\t87837 Polit?cnico\n",
      "29173 c?psulas\t\t56954 antiss?ptica\n"
     ]
    }
   ],
   "source": [
    "awk -F',[ ]*' '($8==4||$8==\"quatro\"){print $1,$2}' /tmp/CorpusABG.csv | column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "It seems all of them are proparoxytone ('proparoxitona') in fact. So lets correct them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "awk -F',[ ]*' 'BEGIN{OFS=\", \"} ($8==4||$8==\"quatro\"){$8=\"proparoxitona\"} {print}' /tmp/CorpusABG.csv > /tmp/tmpABG\n",
    "mv /tmp/tmpABG /tmp/CorpusABG.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Now lets make an histogram for the stress category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "awk -F',[ ]*' '{print $8}' /tmp/CorpusABG.csv | sort | uniq -c | sort -rn | \n",
    "  head -n -1 | nl| \n",
    "  gnuplot -e \"set terminal png; set output 'images/stress_category.png'; set xlabel 'categoria acentual'; set ylabel 'frequencia'; set style fill solid; set boxwidth 1; set title 'corpus abg'; set xtics rotate by 45 right; plot '/dev/stdin' using 1:2:xtic(3) with boxes notitle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "![](images/stress_category.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Many entries have ```?``` in the word (column 2) or lemma (column 5) transcription. The amount is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18007\n"
     ]
    }
   ],
   "source": [
    "awk -F',[ ]*' '($2~/?/)||($4~/?/){print $2, $4, $5}' /tmp/CorpusABG.csv | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "and some examples are given bellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l? l? &l1*\n",
      "tamb?m tamb?m &tA-b6*\n",
      "est? est? &es-t1*\n",
      "s?o s?o &sAW*\n",
      "j? j? &j1*\n",
      "s? s? &s!*\n",
      "? ? a&a*\n",
      "at? at? &a-t5*\n",
      "?s ?s &as*\n",
      "m?e m?e &mA-e*\n"
     ]
    }
   ],
   "source": [
    "awk -F',[ ]*' '($2~/?/)||($4~/?/){print $2, $4, $5}' /tmp/CorpusABG.csv | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Lets create a list of all entries that still need a fix (we will not fix lema)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "#awk -F',[ ]*' 'BEGIN{OFS=\", \"} ($2~/?/){print NR, $2, $4, $5}' /tmp/CorpusABG.csv > /tmp/needfixlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "In the ABG Corpus repository there is a file ```Corpus_Tag_Freq_Trans.txt``` (probably a intermediary file) which has some data that might be used to fix those ```?``` in the corpus file. \n",
    "\n",
    "Lets first download this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "if [ ! -f /tmp/Acentuador.zip ]; then \n",
    "  wget -q https://github.com/SauronGuide/corpusABG/raw/master/7-%20Acentuador.zip -O /tmp/Acentuador.zip\n",
    "fi \n",
    "#unzip -p /tmp/Acentuador.zip \"7- Acentuador/Corpus_Tag_Freq_Trans.txt\" > /tmp/Corpus_Tag_Freq_Trans.txt\n",
    "unzip -p /tmp/Acentuador.zip \"7- Acentuador/Corpus_Transcrito.xlsx\" > /tmp/Corpus_Transcrito.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "And not lets make a script to fix it.\n",
    "\n",
    "For each entry that has ```?``` in it, which is listed in file ```/tmp/needfixlist``` created above, we will find the corresponding entry (same pronounciation) and replace the mispelled word by the vertion in the downloaded file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "#while read line; do\n",
    "#  TRANSC=$(echo $line | awk -F', ' '{print $4}')\n",
    "#  PATT=${TRANSC/\\*/\\\\\\*}\n",
    "#  WORD=$(grep \"$PATT\" /tmp/Corpus_Tag_Freq_Trans.txt | cut -f1 | sed -r 's/[^[:alnum:]]//g' | awk '{print tolower($0)}' | grep \"[àáãâéêíóõôú]\" | head -n 1)\n",
    "#  LINNUM=$(echo $line | awk -F', ' '{print $1}')\n",
    "#  if [ -z \"$WORD\" ]; then\n",
    "#    awk -F',[ ]*' -v linnum=\"$LINNUM\" -v word=\"$WORD\" 'BEGIN{OFS=\",\"} NR==linnum{$2=word} {$1=$1}1' /tmp/CorpusABG.csv > /tmp/tmpabg\n",
    "#    mv /tmp/tmpabg /tmp/CorpusABG.csv  \n",
    "#  fi\n",
    "#done < /tmp/needfixlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Lets create a list of all entries that still need a fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "awk -F',[ ]*' 'BEGIN{OFS=\",\"} ($2~/?/){print NR, $2, $4, $5, $9, $10, $11}' /tmp/CorpusABG.csv > /tmp/needfixlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert /tmp/Corpus_Transcrito.xlsx -> /tmp/Corpus_Transcrito.csv using filter : Text - txt - csv (StarCalc)\n",
      "Overwriting: /tmp/Corpus_Transcrito.csv\n"
     ]
    }
   ],
   "source": [
    "libreoffice --headless --convert-to csv --outdir /tmp/ /tmp/Corpus_Transcrito.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/Corpus_Transcrito.csv: Non-ISO extended-ASCII text\n"
     ]
    }
   ],
   "source": [
    "file /tmp/Corpus_Transcrito.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "iconv -f ISO-8859-1 -t UTF-8//TRANSLIT < /tmp/Corpus_Transcrito.csv  > /tmp/Corpus_Transcrito_utf8.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyboard Interrupt\n"
     ]
    }
   ],
   "source": [
    "while read line; do\n",
    "  LINNUM=$(echo $line | awk -F',' '{print $1}')\n",
    "  TRANSC=$(echo $line | awk -F',' '{print $4}')\n",
    "  F1=$(echo $line | awk -F',' '{print $5}')\n",
    "  F2=$(echo $line | awk -F',' '{print $6}')\n",
    "  F3=$(echo $line | awk -F',' '{print $7}')\n",
    "  WORD=$(awk -F'[ ]*,[ ]*' -v prn=\"$TRANSC\" -v f1=\"$F1\" -v f2=\"$F2\" -v f3=\"$F3\" 'BEGIN{OFS=\",\"} $4==prn&&$8==f1&&$9==f2&&$10==f3{print $1}' /tmp/Corpus_Transcrito_utf8.csv)\n",
    "  if [ ! -z \"$WORD\" ]; then\n",
    "     awk -F',[ ]*' -v linnum=\"$LINNUM\" -v word=\"$WORD\" 'BEGIN{OFS=\",\"} NR==linnum{$2=word} {$1=$1}1' /tmp/CorpusABG.csv > /tmp/tmpabg\n",
    "     mv /tmp/tmpabg /tmp/CorpusABG.csv\n",
    "  fi\n",
    "done < /tmp/needfixlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "# add number of phonemes and syllables\n",
    "awk -F','  'BEGIN{OFS=\",\"} NR==1{printf \"%s\",$0; printf \"%s\",\",NUMFONES,NUMSILABAS\\n\"} NR>1{gsub(/^\\&|\\*$/,\"\",$5); gsub(/^\\&|\\*$/,\"\",$6); gsub(/^\\&|\\*$/,\"\",$7); printf \"%s,\",$0; gsub(/-/,\"\",$5); printf \"%d,%d\\n\", length($5), gsub(/-/,\"\",$7)+1}' /tmp/CorpusABG.csv > /tmp/CorpusABGv2.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.19.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
